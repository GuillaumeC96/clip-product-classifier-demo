#!/usr/bin/env python3
"""
Script de d√©ploiement pour le nouveau mod√®le CLIP
"""

import os
import json
import torch
from azure.ai.ml import MLClient
from azure.ai.ml.entities import (
    ManagedOnlineEndpoint,
    ManagedOnlineDeployment,
    Model,
    Environment,
    CodeConfiguration,
)
from azure.identity import DefaultAzureCredential
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv('.env_azure_production')

def load_env_file():
    """Charger les variables d'environnement depuis le fichier .env_azure_production"""
    env_file = '.env_azure_production'
    if os.path.exists(env_file):
        with open(env_file, 'r') as f:
            for line in f:
                if line.strip() and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value
        print(f"‚úÖ Variables d'environnement charg√©es depuis {env_file}")
    else:
        print(f"‚ö†Ô∏è Fichier {env_file} non trouv√©")

def verify_model():
    """V√©rifier le nouveau mod√®le"""
    model_path = "new_clip_product_classifier.pth"
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Mod√®le non trouv√©: {model_path}")
    
    print(f"üìÅ Mod√®le trouv√©: {model_path}")
    print(f"üìä Taille: {os.path.getsize(model_path) / (1024**3):.2f} GB")
    
    # V√©rifier la structure du mod√®le
    try:
        checkpoint = torch.load(model_path, map_location='cpu')
        print("üîç Structure du mod√®le:")
        for key in checkpoint.keys():
            if isinstance(checkpoint[key], dict):
                print(f"  - {key}: {list(checkpoint[key].keys())}")
            else:
                print(f"  - {key}: {type(checkpoint[key])}")
        return True
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification du mod√®le: {e}")
        return False

def create_ml_client():
    """Cr√©er le client ML"""
    subscription_id = os.getenv('AZURE_SUBSCRIPTION_ID')
    resource_group = os.getenv('AZURE_RESOURCE_GROUP')
    workspace_name = os.getenv('AZURE_WORKSPACE_NAME')
    
    if not all([subscription_id, resource_group, workspace_name]):
        raise ValueError("Variables d'environnement Azure manquantes")
    
    credential = DefaultAzureCredential()
    ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)
    
    print(f"‚úÖ Client ML cr√©√© pour {workspace_name}")
    return ml_client

def create_endpoint(ml_client, endpoint_name="clip-classifier-endpoint"):
    """Cr√©er ou mettre √† jour l'endpoint"""
    try:
        # V√©rifier si l'endpoint existe
        try:
            endpoint = ml_client.online_endpoints.get(endpoint_name)
            print(f"‚úÖ Endpoint existant trouv√©: {endpoint_name}")
            return endpoint
        except:
            # Cr√©er un nouvel endpoint
            endpoint = ManagedOnlineEndpoint(
                name=endpoint_name,
                description="Endpoint pour le nouveau mod√®le CLIP",
                auth_mode="key"
            )
            
            endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()
            print(f"‚úÖ Nouvel endpoint cr√©√©: {endpoint_name}")
            return endpoint
            
    except Exception as e:
        print(f"‚ùå Erreur lors de la cr√©ation de l'endpoint: {e}")
        raise

def register_model(ml_client, model_name="new-clip-classifier"):
    """Enregistrer le nouveau mod√®le"""
    try:
        # V√©rifier si le mod√®le existe d√©j√†
        try:
            model = ml_client.models.get(model_name, version="1")
            print(f"‚úÖ Mod√®le existant trouv√©: {model_name}")
            return model
        except:
            # Enregistrer le nouveau mod√®le
            model = Model(
                name=model_name,
                path="new_clip_product_classifier.pth",
                description="Nouveau mod√®le CLIP fine-tun√©",
                version="1"
            )
            
            model = ml_client.models.create_or_update(model)
            print(f"‚úÖ Nouveau mod√®le enregistr√©: {model_name}")
            return model
            
    except Exception as e:
        print(f"‚ùå Erreur lors de l'enregistrement du mod√®le: {e}")
        raise

def create_environment(ml_client, env_name="clip-env-v2"):
    """Cr√©er l'environnement pour le nouveau mod√®le"""
    try:
        # V√©rifier si l'environnement existe
        try:
            env = ml_client.environments.get(env_name, version="1")
            print(f"‚úÖ Environnement existant trouv√©: {env_name}")
            return env
        except:
            # Cr√©er un nouvel environnement
            env = Environment(
                name=env_name,
                description="Environnement pour le nouveau mod√®le CLIP",
                image="mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest",
                conda_file="azure_ml_api/environment.yml",
                version="1"
            )
            
            env = ml_client.environments.create_or_update(env)
            print(f"‚úÖ Nouvel environnement cr√©√©: {env_name}")
            return env
            
    except Exception as e:
        print(f"‚ùå Erreur lors de la cr√©ation de l'environnement: {e}")
        raise

def create_deployment(ml_client, endpoint_name, model, environment, deployment_name="new-clip-deployment"):
    """Cr√©er le d√©ploiement"""
    try:
        # V√©rifier si le d√©ploiement existe
        try:
            deployment = ml_client.online_deployments.get(endpoint_name, deployment_name)
            print(f"‚úÖ D√©ploiement existant trouv√©: {deployment_name}")
            return deployment
        except:
            # Cr√©er un nouveau d√©ploiement
            deployment = ManagedOnlineDeployment(
                name=deployment_name,
                endpoint_name=endpoint_name,
                model=model,
                environment=environment,
                code_configuration=CodeConfiguration(
                    source="azure_ml_api",
                    scoring_script="score.py"
                ),
                instance_type="Standard_DS2_v2",  # Instance minimale pour √©conomiser
                instance_count=1,
                description="D√©ploiement du nouveau mod√®le CLIP"
            )
            
            deployment = ml_client.online_deployments.begin_create_or_update(deployment).result()
            print(f"‚úÖ Nouveau d√©ploiement cr√©√©: {deployment_name}")
            return deployment
            
    except Exception as e:
        print(f"‚ùå Erreur lors de la cr√©ation du d√©ploiement: {e}")
        raise

def set_traffic(ml_client, endpoint_name, deployment_name):
    """D√©finir le trafic vers le nouveau d√©ploiement"""
    try:
        endpoint = ml_client.online_endpoints.get(endpoint_name)
        endpoint.traffic = {deployment_name: 100}
        endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()
        print(f"‚úÖ Trafic d√©fini √† 100% vers {deployment_name}")
        return endpoint
    except Exception as e:
        print(f"‚ùå Erreur lors de la d√©finition du trafic: {e}")
        raise

def get_endpoint_info(ml_client, endpoint_name):
    """R√©cup√©rer les informations de l'endpoint"""
    try:
        endpoint = ml_client.online_endpoints.get(endpoint_name)
        print(f"\nüéØ Informations de l'endpoint:")
        print(f"   - Nom: {endpoint.name}")
        print(f"   - URL: {endpoint.scoring_uri}")
        print(f"   - √âtat: {endpoint.provisioning_state}")
        print(f"   - Trafic: {endpoint.traffic}")
        
        # R√©cup√©rer la cl√© API
        keys = ml_client.online_endpoints.get_keys(endpoint_name)
        print(f"   - Cl√© API: {keys.primary_key[:10]}...")
        
        return endpoint.scoring_uri, keys.primary_key
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des informations: {e}")
        raise

def main():
    """Fonction principale"""
    print("üöÄ D√©ploiement du nouveau mod√®le CLIP")
    print("=" * 50)
    
    try:
        # 1. Charger les variables d'environnement
        load_env_file()
        
        # 2. V√©rifier le mod√®le
        if not verify_model():
            return
        
        # 3. Cr√©er le client ML
        ml_client = create_ml_client()
        
        # 4. Cr√©er l'endpoint
        endpoint_name = "clip-classifier-endpoint"
        endpoint = create_endpoint(ml_client, endpoint_name)
        
        # 5. Enregistrer le mod√®le
        model = register_model(ml_client)
        
        # 6. Cr√©er l'environnement
        environment = create_environment(ml_client)
        
        # 7. Cr√©er le d√©ploiement
        deployment_name = "new-clip-deployment"
        deployment = create_deployment(ml_client, endpoint_name, model, environment, deployment_name)
        
        # 8. D√©finir le trafic
        set_traffic(ml_client, endpoint_name, deployment_name)
        
        # 9. R√©cup√©rer les informations
        endpoint_url, api_key = get_endpoint_info(ml_client, endpoint_name)
        
        print(f"\n‚úÖ D√©ploiement termin√© avec succ√®s!")
        print(f"üîó URL de l'endpoint: {endpoint_url}")
        print(f"üîë Cl√© API: {api_key[:10]}...")
        
        # Mettre √† jour le fichier .env_azure_production
        with open('.env_azure_production', 'a') as f:
            f.write(f"\n# Nouveau mod√®le d√©ploy√©\n")
            f.write(f"AZURE_ML_ENDPOINT_URL={endpoint_url}\n")
            f.write(f"AZURE_ML_API_KEY={api_key}\n")
        
        print(f"\nüìù Variables d'environnement mises √† jour dans .env_azure_production")
        
    except Exception as e:
        print(f"‚ùå Erreur lors du d√©ploiement: {e}")
        raise

if __name__ == "__main__":
    main()
